---
# Page settings
layout: default
keywords:
comments: false

# Hero section
title: Section 8
description: Hyperparameter Tuning and Tensorboard


# Micro navigation
micro_nav: true

---

Coming soon!

<!--

# Hyperparameter Tuning

Lots of hyperparameters are involved in the design of a deep neural network. **What are some examples?**


Finding the best set of hyperparameters for a task creates a second optimization challenge.  Here are a couple strategies for solving this problem.

### Random Search and Grid Search


Consider the following function $$f(x,y) = g(x) + h(y)$$ over parameters $$x,y$$ and the maximization problem:

$$\max_{x,y} f(x,y).$$

Assume you only have access to $$f(x,y)$$ through an *oracle* (i.e. you can evaluate $$f$$ at a certain point $$(x,y)$$, but you do not know the functional form of $$f$$).  **How would you find the optimal values of $$x$$ and $$y$$?** 

 - Choose a range for the values of $$x$$ and $$y$$  and sample a grid of points in this range.
 - Evaluate a numerical gradient in the hyperparameter space and use this to inform the choice of values for $$x$$ and $$y$$.  The challenge with this method is that unlike an iteration of model training, each evaluation of hyperparameters is very costly making it infeasible to try many combinations of hyperparameters.

Assume that you know, 

$$f(x,y) = g(x) + h(y) \approx g(x).$$

**Would grid search still be a good strategy?  If not can you modify it to improve the results?**

- The function $f$ mostly depends on $$x$$. Thus, a grid search strategy will waste a lot of iterations testing for different values of $$y$$.  If you have a finite number of evaluations of $$(x,y)$$, then a better strategy would be randomly sampling  $$x$$ and $$y$$ in a certain range, that way each sample tests a different value of each hyperparameter.

{% include image.html description="An illustration of how random search can improve on grid search of hyperparameters.  'This failure of grid search is the rule rather than the exception in high dimensional hyper-parameter optimization' (Bergstra & Bengio, 2011)." link="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf" image="section/7/random-grid.png" caption="true"%}

**What is a weakness or assumption of random search?**

- Random search assumes that the hyperparameters are uncorrelated (for example, batch size and learning rate are positively correlated: a smaller batch size generally implies a smaller learning rate). Ideally, you would sample hyperparameters from a joint distribution that takes into account this understanding.  Additionally, it does not use the results of previous iterations to inform how you choose samples for the future iterations.  This is the motivation behind Bayesian optimization stratgies.

### Bayesian Optimization

Bayesian inference is a form of statistical inference that uses Bayes' Theorem to incorperate prior knowledge of paramters when performing estimation.  Bayes' Theorem is a simple, yet extermely powerful, formula realating conditional and joint distributions of random variables.  Let $$M$$ be the random variable representing the quality of our model and $$\theta$$ the random variable representing our hyperparameters.  Then Bayes rules relates the distributions $$p(\theta \mid X)$$ (posterior), $$p(X\mid\theta)$$ (likelihood), $$p(\theta)$$ (prior) and $$p(X)$$ (marginal) as:

$$p(\theta\mid M) = \frac{p(M \mid \theta)p(\theta)}{p(M)}$$

**How could you use Bayes' Rule to improve random search?**
- By using a prior on our hyperparameters you can incorperate prior knowldege about the relationship between hyperparameters.  By sampling from the posterior distribution instead of a uniform joint distribution you can incorperate the results of our previous samples to improve our search process.

Lets reconsider the optimization problem of finding the maximum of $$f(x,y)$$.  A Bayesian optimization strategy would: 

  - Initialize a prior on the parameters $$x$$ and $$y$$. 
  - Sample an initial point $$(x,y)$$ to evaluate $$f$$ with.  
  - Use the result of $$f(x,y)$$ to update the posterior of $$x,y$$.
  - Repeat the last two steps.

Here is a good [code base](https://github.com/fmfn/BayesianOptimization) for implementing Bayesian Optimization with Gaussian processes.


{% include image.html description="With each iteration 'the algorithm balances its needs of exploration and exploitation' (Nogueira)." link="https://github.com/fmfn/BayesianOptimization" image="section/7/bayesopt.gif" caption="true"%}


-->







