---
# Page settings
layout: default
keywords:
comments: false

# Hero section
title: Section 1
description: The goal of this section is to (i) let you chat with other students about projects, (ii) give you an idea of what makes a successful CS230 project, (iii) introduce some common datasets and tasks in deep learning.

# Micro navigation
micro_nav: true

---

# Welcome to CS230!

### Mixer
Let’s go around the room and introduce ourselves. Let’s share things like - name, major (or company if SCPD), previous experience with machine/deep learning, project interest etc.

### What are sections?

Sections are hourly seminars held every week by the course assistants on various topics in deep learning.  The topics are split between practice, such as tutorials to Tensorflow and Pytorch, and theory, such as backpropagation and regularization.  Attendance is not required for the sections, but the material covered in section is **fair game for the midterm**.


# Getting started with your project

### What is the project?

One of CS230's main goals is to prepare you to apply machine learning algorithms to real-world tasks, or to leave you well-qualified to start machine learning or AI research. The final project is intended to start you in these directions and is the main focus of CS230.  So what is the project?

 * Form groups of 1-3 students (4 is ok with TA approval).
 * Project deliverables:
   - [Proposal](/project/#proposal) (01/22)
   - [Milestone](/project/#milestone) (02/19)
   - [Poster](/project/#poster) (03/20)
   - [Final Report](/project/#final-report) (03/19)
 * Project office hours (15 mins per group per week) with mandatory meetings for the first one, the week after proposal, the week after milestone, and the week before final submission.
 * The project can be combined with the final project of another class, but must be deep learning focused.

### Types of projects

Historically, students who have succeeded in their CS230 projects have done one of the following:

 * **Used popular network architectures to perform a novel task.** For example, some students have used the YOLO algorithm to detect humans on images taken from their drones. They then cropped the humans out of the pictures and filled-in the humans position with the correct background using a Generative Adversarial Network. Another example: students have fine-tuned existing networks to perform state of the art accuracy in Tree Species Identification.
 * **Came up with a custom architecture to perform an existing (or novel task).** For example, students made changes to the popular U-net algorithm to improve performance on a chosen task such as brain tumor segmentation. Another example: students have improved accuracy on a task by adding and training an attention mechanism on top of the existing RNN architecture.
 * **Re-implemented a famous research paper.** For example, students have tried to re-implement the popular WaveNet algorithm with their own code.
 * **Did a research project.** For example, students have designed a neural network algorithm to debias word vectors using a novel technique. They then submitted their paper to a conference.

 Note that the common denominator of these projects is that students have contributed something *novel*. Of course, the above categories are not the only ones. We encourage students to talk with their mentors to figure out if their project idea is aligned with CS230’s expectations.


### Which came first the Data or the Application?

Deep learning models can handle and sometime need a lot of data.  While, you might have an awesome new application for deep learning, without a decent dataset it will not lead to a good project.  Likewise, an amazing dataset without an application that deep learning can solve will not lead to a good project.  So how to get started?  Here are some helpful hints.


<!-- {% include image.html description="" link="https://archive.tedx.amsterdam/2015/07/which-came-first/" image="section/1/chicken-egg.jpg" %} -->


#### Choosing a project idea
 * Look at [past projects](/past-projects) in CS230 and other machine learning/deep learning classes at Stanford ([CS229](http://cs229.stanford.edu/), [CS229A](https://web.stanford.edu/class/cs229a/), [CS221](http://web.stanford.edu/class/cs221/), [CS224N](http://web.stanford.edu/class/cs224n/), [CS231N](http://cs231n.stanford.edu/)).
 * Look at recent deep learning research papers using an academic search engine such as [Google Scholar](http://scholar.google.com), searching through main machine learning conferences such as [ICML](https://icml.cc/) and [NIPS](https://nips.cc/), or going through this [blog](https://paperswithcode.com/sota).
 * Check out these great GitHub repositories: 
   - [Awesome NLP](https://github.com/keon/awesome-nlp)
   - [Awesome GAN](https://github.com/nightrome/really-awesome-gan)
   - [Awesome DL](https://github.com/endymecy/awesome-deeplearning-resources/blob/master/papers/2018/dl.md)

#### Finding a dataset

 * Use Google's [Dataset Search](https://toolbox.google.com/datasetsearch) tool.
 * Look through Kaggle's [datasets](https://www.kaggle.com/datasets) and [competitions](https://www.kaggle.com/competitions) (current and past).
 * Use a dataset from your own research.
 * Use a standard benchmarked dataset for a specific task.

#### Building a dataset
 * Use a web scraping library such as [MechanicalSoup](https://mechanicalsoup.readthedocs.io/en/stable/).
 * Generate synthetic data from a model currently being used in your research.
 * Collect data with your hands (Kian once spent two days on the Stanford campus collecting short audio recordings of students saying "activate" to build a speech recognition algorithm).

 The focus of CS230's project is on developing deep learning models.  Finding the right application and dataset is very important, but it is only the first piece in the puzzle.  **Don't spend too much time on data collection.**  In order to maximize your time spent on developing models, it might be a good idea to look as some well defined tasks and datasets. 

# Deep learning applications and datasets

### Computer Vision 

{% include image.html description="Examples of computer vision tasks" link="https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning" image="section/1/vision.png" %}

* Image Classification 
  - [Imagenet](http://www.image-net.org/): 14M images and more than 20k classes.
  - [MNIST](http://yann.lecun.com/exdb/mnist/): Dataset of handwritten digits with 10 classes. 70k low resolution images (50Mb)
  - [CIFAR 10/100](https://www.cs.toronto.edu/~kriz/cifar.html): Dataset with 60k low resolution images (10 and 100 classes respectively)
* Object Detection
  - [COCO](http://cocodataset.org/#home): Dataset for object detection, image segmentation and image captioning. It has more than 200k images with 80 object categories.
  - [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/): Dataset of 20k images labelled with bounding boxes and 20 classes.
  - [Open Images](https://storage.googleapis.com/openimages/web/index.html): 9M images that have been annotated with image-level labels and object bounding boxes.


### Sequence Models

{% include image.html description="Examples of NLP and speech applications" link="https://www.coursera.org/learn/nlp-sequence-models" image="section/1/nlp.png" %}

* Natural Language Processing
  - [Squad](https://rajpurkar.github.io/SQuAD-explorer/): The Stanford Question Answering Dataset
  - [Google Books n-grams](https://books.google.com/ngrams)
  - [Yelp Open Dataset](https://www.yelp.com/dataset): A subset of Yelp's businesses, reviews, and user data.
* Time Series
  - Yahoo Finance API
* Video Classification
  - [Youtube-8M](https://research.google.com/youtube8m/)
  - [Moments in Time](http://moments.csail.mit.edu/)
  - [Kinetics-600](https://deepmind.com/research/open-source/open-source-datasets/kinetics/)
* Music
  - [Million Song](https://labrosa.ee.columbia.edu/millionsong/): A collection of audio features and metadata for a million contemporary popular music tracks.
* Computational Biology
  - [Deep Bind](http://tools.genes.toronto.edu/deepbind/)




### Miscellaneous

{% include image.html description="Results of the image-to-image translation model CycleGAN Zhu, Park et al." link="https://github.com/junyanz/CycleGAN" image="section/1/gan.gif" %}

 * Generative Adversarial Networks
   - [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html): a large-scale face attributes dataset with more than 200K celebrity images, each with 40 attribute annotations.
 * Recomendation Systems and Autoencoders
   - [MovieLens](https://grouplens.org/datasets/movielens/): 20 million ratings and 465,000 tag applications applied to 27,000 movies by 138,000 users. 
   - [Netflix Prize Challenge](https://www.netflixprize.com/index.html):
 * Adversarial Attack and Defense
   - [CleverHans](https://github.com/tensorflow/cleverhans): A Python library to benchmark machine learning systems' vulnerability to adversarial examples.
 * Deep Reinforcement Learning
   - [OpenAI Gym](https://gym.openai.com/): A toolkit for developing and comparing reinforcement learning algorithms.
 * Style Transfer


# Questions

Have fun getting started on your projects!


