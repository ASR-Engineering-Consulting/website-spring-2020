---
# Page settings
layout: default
keywords:
comments: false

# Hero section
title: Section 5
description: TensorFlow and PyTorch


# Micro navigation
micro_nav: true

---

# Introduction

Several different deep learning frameworks exist today, each with their own strengths, weaknesses, and user base. In this section, we’ll focus on the two most popular frameworks today: TensorFlow and PyTorch.

The main difference between those frameworks is - code notwithstanding - the way in which they create and run computations. In general, deep learning frameworks represent neural networks as computational graphs:

{% include image.html description="TensorFlow Computational Graph." link="https://www.TensorFlow.org/guide/graphs" image="section/5/tfgraph.png" caption="true" width="100px" %}

Our variables, such as the weights, biases, and loss function, are graph nodes defined before training. During training, the graph is run to execute the computations. 

TensorFlow and PyTorch, our two chosen frameworks, handle this computational graph differently. In TensorFlow, the graph is static. That means that we create and connect all the variables at the beginning, and initialize them into a static (unchanging) session. This session and graph persists and is reused: it is not rebuilt after each iteration of training, making it efficient. However, with a static graph, variable sizes have to be defined at the beginning, which can be non-convenient for some applications, such as NLP with variable length inputs.

On the contrary, PyTorch uses a dynamic graph. That means that the computational graph is built up dynamically, immediately after we declare variables. This graph is thus rebuilt after each iteration of training. Dynamic graphs are flexible and allow us modify and inspect the internals of the graph at any time. The main drawback is that it can take time to rebuild the graph. Either PyTorch or TensorFlow can be more efficient depending on the specific application and implementation.

Recently, a new version of TensorFlow, TensorFlow 2.0 Alpha, was released. This new TensorFlow uses dynamic graphs as well. We’ll take a glance at it in this section.

Now, let’s cover two main topics: 

1. We’ll walk through how to build a full TensorFlow deep learning pipeline from scratch. A PyTorch notebook is also available as a comparison. 
2. We will compare and contrast PyTorch vs. TensorFlow vs. TensorFlow 2.0 code.

# TensorFlow Deep Learning Pipeline

Here is an possible list of steps to implement a deep learning pipeline:

1. Download the dataset
2. Load and preprocess the dataset
3. Define the model
4. Define the loss function and optimizer
5. Define the evaluation metric
6. Train the network on the training data
7. Report results on the train and test data

Let’s look at a TensorFlow notebook in Colab to see how to build each of those steps. 

 [**TensorFlow Walkthrough**](https://colab.research.google.com/drive/1HzN2f0Mypj0r2rKJdKYCjczM1WzJyoaV) 

[**PyTorch Walkthrough (for reference)**](https://colab.research.google.com/drive/1a2KshOZVj4eqYsfFqlBHB66CUIERKHj5)

# Comparing TensorFlow, PyTorch, and TensorFlow 2.0

The main differences between these frameworks are in the way in which variables are assigned and the computational graph is run. TensorFlow 2.0 works similarly to PyTorch. 

{% include image.html description="TensorFlow 1 and 2." image="section/5/tf1and2.png" caption="true"%}

With TensorFlow 2.0, we don’t initialize and run a session with placeholders. Instead, the computational graph is built up dynamically as we declare variables, and calling a function with an input runs the graph and provides the output, like a standard Python function.

{% include image.html description="TensorFlow 1." image="section/5/tf1.png" caption="true"%}

{% include image.html description="TensorFlow 2." image="section/5/tf2.png" caption="true"%}

{% include image.html description="PyTorch." image="section/5/PyTorch.png" caption="true"%}

<!--

# Midterm Review

We will now review additional material that will appear on the midterm exam.  

  * [Slides](https://docs.google.com/presentation/d/1Vgbv1D212r67qAFODDlxvCka-huBoqGWYXJ8PkHu2-o/edit?usp=sharing)
  * [Questions](https://www.mentimeter.com/s/1925b59f81e274227476440ee78bb318/099a806113b9)

-->




